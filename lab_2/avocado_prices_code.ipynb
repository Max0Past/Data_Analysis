{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36929e94",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h1 style=\"color:#1565c0; font-size:2.8em; font-weight:bold; margin-bottom:0.2em; margin-top:0.5em;\">Практична робота №2</h1>\n",
    "<h3 style=\"color:#1976d2; margin-top:0; font-weight:normal;\">Побудова та оцiнювання якостi\n",
    "моделей класифiкацiї та регресiї засобами бiблiотеки <b>Scikit-Learn Python</b></h3>\n",
    "<br>\n",
    "<br>\n",
    "<b>Варіант 12</b><br>\n",
    "<b>Автори:</b><br>\n",
    "Плахтій Злата, КА-32<br>\n",
    "Пастушенко Максим, КА-33<br>\n",
    "Романов Фелікс, КА-33\n",
    "</div>\n",
    "\n",
    "<b>Мета:</b> Метою роботи є побудова та оцiнювання якостi моделей:\n",
    "- дерев рiшень,\n",
    "- опорних векторiв,\n",
    "- логiстичної регресiї,\n",
    "- наївної баєсiвської моделi\n",
    "для класифiкацiї та регресiї засобами бiблiотеки Scikit-Learn Python.\n",
    "\n",
    "<b>Хід роботи:</b>\n",
    "1. Підготувати дані.\n",
    "2. Представити початкових даних графiчно.\n",
    "3. Розбити данi на навчальний та валiдацiйний набори.\n",
    ". Побудувати на навчальному наборi даних моделi класифiкацiї або регресiї заданi згiдно з варiантом.\n",
    "4. Представити моделi графiчно (наприклад вивести частину дерева рiшень, побудувати лiнiю регресiї тощо).\n",
    "5. Виконати прогнози на основi побудованих моделей.\n",
    "6. Для кожної з моделей оцiнити, чи має мiсце перенавчання.\n",
    "7. В задачах регресiї розрахувати для кожної моделi наступнi критерiї якостi, окремо на навчальнiй та валiдацiйнiй множинах:\n",
    "\n",
    "    • коефiцiєнт детермiнацiї R2,\n",
    "    \n",
    "    • помилки RMSE, MAE та MAPE.\n",
    "\n",
    "8. Спробувати виконати решiтчастий пошук (grid search) для пiдбору гiперпараметрiв моделей.\n",
    "9. Зробити висновки про якiсть роботи моделей на дослiджених даних. На\n",
    "основi критерiїв якостi спробувати обрати найкращу модель.\n",
    "10. Навчити моделi на пiдмножинах навчальних даних. Оцiнити, наскiльки\n",
    "розмiр навчальної множини впливає на якiсть моделi.\n",
    "11. Кожний варiант мiстить два набори даних. Дослiдити обидва набори за\n",
    "наведеними вище етапами.\n",
    "\n",
    "<b>Завдання:</b><br>\n",
    "Побудувати моделi регресiї на основi методу опорних векторiв:<br><br>\n",
    "• Моделi нелiнiйної регресiї SVR(kernel=\"poly\") з полiномiальним ядром. <br>\n",
    "  Розглянути полiноми рiзного ступеня degree та рiзнi комбiнацiї гiперпараметрiв epsilon i C, наприклад: epsilon=0.1 i C=0.01; epsilon=0.1 i C=100.<br><br>\n",
    "• Настроїти гiперпараметри epsilon i C, використовуючи решітчастий пошук.<br><br>\n",
    "Початковi данi:<br>\n",
    "(б) [avocado_prices.csv](https://www.kaggle.com/datasets/neuromusic/avocado-prices)\n",
    "для якогось коміта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4b4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdfbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стовпці датасету:\n",
      "['Unnamed: 0', 'Date', 'AveragePrice', 'Total Volume', '4046', '4225', '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags', 'type', 'year', 'region']\n",
      "\n",
      "\n",
      "Інформація про датасет:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18249 entries, 0 to 18248\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    18249 non-null  int64  \n",
      " 1   Date          18249 non-null  object \n",
      " 2   AveragePrice  18249 non-null  float64\n",
      " 3   Total Volume  18249 non-null  float64\n",
      " 4   4046          18249 non-null  float64\n",
      " 5   4225          18249 non-null  float64\n",
      " 6   4770          18249 non-null  float64\n",
      " 7   Total Bags    18249 non-null  float64\n",
      " 8   Small Bags    18249 non-null  float64\n",
      " 9   Large Bags    18249 non-null  float64\n",
      " 10  XLarge Bags   18249 non-null  float64\n",
      " 11  type          18249 non-null  object \n",
      " 12  year          18249 non-null  int64  \n",
      " 13  region        18249 non-null  object \n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 1.9+ MB\n",
      "\n",
      "\n",
      "Описові статистики:\n",
      "         Unnamed: 0  AveragePrice  Total Volume          4046          4225  \\\n",
      "count  18249.000000  18249.000000  1.824900e+04  1.824900e+04  1.824900e+04   \n",
      "mean      24.232232      1.405978  8.506440e+05  2.930084e+05  2.951546e+05   \n",
      "std       15.481045      0.402677  3.453545e+06  1.264989e+06  1.204120e+06   \n",
      "min        0.000000      0.440000  8.456000e+01  0.000000e+00  0.000000e+00   \n",
      "25%       10.000000      1.100000  1.083858e+04  8.540700e+02  3.008780e+03   \n",
      "50%       24.000000      1.370000  1.073768e+05  8.645300e+03  2.906102e+04   \n",
      "75%       38.000000      1.660000  4.329623e+05  1.110202e+05  1.502069e+05   \n",
      "max       52.000000      3.250000  6.250565e+07  2.274362e+07  2.047057e+07   \n",
      "\n",
      "               4770    Total Bags    Small Bags    Large Bags    XLarge Bags  \\\n",
      "count  1.824900e+04  1.824900e+04  1.824900e+04  1.824900e+04   18249.000000   \n",
      "mean   2.283974e+04  2.396392e+05  1.821947e+05  5.433809e+04    3106.426507   \n",
      "std    1.074641e+05  9.862424e+05  7.461785e+05  2.439660e+05   17692.894652   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00       0.000000   \n",
      "25%    0.000000e+00  5.088640e+03  2.849420e+03  1.274700e+02       0.000000   \n",
      "50%    1.849900e+02  3.974383e+04  2.636282e+04  2.647710e+03       0.000000   \n",
      "75%    6.243420e+03  1.107834e+05  8.333767e+04  2.202925e+04     132.500000   \n",
      "max    2.546439e+06  1.937313e+07  1.338459e+07  5.719097e+06  551693.650000   \n",
      "\n",
      "               year  \n",
      "count  18249.000000  \n",
      "mean    2016.147899  \n",
      "std        0.939938  \n",
      "min     2015.000000  \n",
      "25%     2015.000000  \n",
      "50%     2016.000000  \n",
      "75%     2017.000000  \n",
      "max     2018.000000  \n",
      "\n",
      "\n",
      "Перші 5 рядків датасету:\n",
      "   Unnamed: 0        Date  AveragePrice  Total Volume     4046       4225  \\\n",
      "0           0  2015-12-27          1.33      64236.62  1036.74   54454.85   \n",
      "1           1  2015-12-20          1.35      54876.98   674.28   44638.81   \n",
      "2           2  2015-12-13          0.93     118220.22   794.70  109149.67   \n",
      "3           3  2015-12-06          1.08      78992.15  1132.00   71976.41   \n",
      "4           4  2015-11-29          1.28      51039.60   941.48   43838.39   \n",
      "\n",
      "     4770  Total Bags  Small Bags  Large Bags  XLarge Bags          type  \\\n",
      "0   48.16     8696.87     8603.62       93.25          0.0  conventional   \n",
      "1   58.33     9505.56     9408.07       97.49          0.0  conventional   \n",
      "2  130.50     8145.35     8042.21      103.14          0.0  conventional   \n",
      "3   72.58     5811.16     5677.40      133.76          0.0  conventional   \n",
      "4   75.78     6183.95     5986.26      197.69          0.0  conventional   \n",
      "\n",
      "   year  region  \n",
      "0  2015  Albany  \n",
      "1  2015  Albany  \n",
      "2  2015  Albany  \n",
      "3  2015  Albany  \n",
      "4  2015  Albany  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 1.1. Завантаження та огляд даних\n",
    "# ------------------------------\n",
    "# ------------- Налаштування -------------\n",
    "FILE_PATH = 'data/avocado.csv'            # новий відносний шлях до файлу\n",
    "TARGET = 'AveragePrice'\n",
    "SAVE_PATH = 'data/avocado_prepared.csv'   # зберігати в тій самій папці (опціонально)\n",
    "\n",
    "# Перевірка наявності файлу\n",
    "if not Path(FILE_PATH).exists():\n",
    "    raise FileNotFoundError(f\"Файл не знайдено: {Path(FILE_PATH).resolve()}\")\n",
    "\n",
    "# Переконайся, що папка для збереження існує\n",
    "out_dir = Path(SAVE_PATH).parent\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Завантажити дані та перевірити структуру \n",
    "if not os.path.exists(FILE_PATH):\n",
    "    raise FileNotFoundError(f\"Файл не знайдено: {FILE_PATH}\")\n",
    "\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Показати імена стовпців\n",
    "print(\"Стовпці датасету:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Показати інформацію про датасет\n",
    "print(\"Інформація про датасет:\")\n",
    "df.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "# Показати описові статистики\n",
    "print(\"Описові статистики:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Показати перші рядки датасету\n",
    "print(\"Перші 5 рядків датасету:\")\n",
    "print(df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56592ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Видалені службові колонки: ['year']\n",
      "\n",
      "Створено часові ознаки: year, month, dayofweek, day\n",
      "\n",
      "Категоріальних колонок type/region не знайдено для кодування\n",
      "\n",
      "PLU-колонки 4046/4225/4770 не знайдено або вже перейменовано\n",
      "\n",
      "Пропусків у датасеті не знайдено\n",
      "\n",
      "Дублікатів не знайдено\n",
      "\n",
      "Масштабовано числові ознаки (StandardScaler). Кількість колонок: 12\n",
      "\n",
      "Підготовка завершена. Збережено: data/avocado_prepared.csv\n",
      "\n",
      "Розміри після підготовки: (18249, 68)\n",
      "        Date  AveragePrice  Total Volume  plu_4046  plu_4225  plu_4770  \\\n",
      "0 2015-12-27          1.33     -0.227716 -0.230816 -0.199902 -0.212091   \n",
      "1 2015-12-20          1.35     -0.230427 -0.231103 -0.208054 -0.211997   \n",
      "2 2015-12-13          0.93     -0.212085 -0.231007 -0.154478 -0.211325   \n",
      "3 2015-12-06          1.08     -0.223444 -0.230741 -0.185350 -0.211864   \n",
      "4 2015-11-29          1.28     -0.231538 -0.230891 -0.208719 -0.211834   \n",
      "\n",
      "   Total Bags  Small Bags  Large Bags  XLarge Bags  ...  region_SouthCentral  \\\n",
      "0   -0.234170   -0.232647   -0.222352     -0.17558  ...                False   \n",
      "1   -0.233350   -0.231568   -0.222335     -0.17558  ...                False   \n",
      "2   -0.234730   -0.233399   -0.222311     -0.17558  ...                False   \n",
      "3   -0.237096   -0.236568   -0.222186     -0.17558  ...                False   \n",
      "4   -0.236718   -0.236154   -0.221924     -0.17558  ...                False   \n",
      "\n",
      "   region_Southeast  region_Spokane  region_StLouis  region_Syracuse  \\\n",
      "0             False           False           False            False   \n",
      "1             False           False           False            False   \n",
      "2             False           False           False            False   \n",
      "3             False           False           False            False   \n",
      "4             False           False           False            False   \n",
      "\n",
      "   region_Tampa  region_TotalUS  region_West  region_WestTexNewMexico  \\\n",
      "0         False           False        False                    False   \n",
      "1         False           False        False                    False   \n",
      "2         False           False        False                    False   \n",
      "3         False           False        False                    False   \n",
      "4         False           False        False                    False   \n",
      "\n",
      "       year  \n",
      "0 -1.221282  \n",
      "1 -1.221282  \n",
      "2 -1.221282  \n",
      "3 -1.221282  \n",
      "4 -1.221282  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 1.2. підготовка даних\n",
    "# ------------------------------\n",
    "\n",
    "# Видалити зайві стовпці \n",
    "# Часті «службові» назви: 'Unnamed: 0', 'Unnamed:0', 'X' або окремий стовпець year, що дублює дату\n",
    "drop_candidates = ['Unnamed: 0', 'Unnamed:0', 'X', 'year']\n",
    "drop_cols = [c for c in drop_candidates if c in df.columns]\n",
    "if drop_cols:\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "    print('\\nВидалені службові колонки:', drop_cols)\n",
    "\n",
    "# Конвертувати Date у datetime \n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    # Якщо є пропуски у Date, краще видалити такі рядки\n",
    "    n_date_na = df['Date'].isna().sum()\n",
    "    if n_date_na:\n",
    "        print(f\"\\nПримітка: знайдено {n_date_na} рядків з некоректною датою. Видаляю їх.\")\n",
    "        df = df.dropna(subset=['Date']).reset_index(drop=True)\n",
    "    # Додаткові часові ознаки\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['dayofweek'] = df['Date'].dt.dayofweek\n",
    "    df['day'] = df['Date'].dt.day\n",
    "    print('\\nСтворено часові ознаки: year, month, dayofweek, day')\n",
    "else:\n",
    "    print('\\nУ датасеті відсутня колонка Date')\n",
    "\n",
    "# Кодування категорій (type, region) \n",
    "cat_cols = [c for c in ['type', 'region'] if c in df.columns]\n",
    "if cat_cols:\n",
    "    # Використаємо get_dummies для простоти. drop_first=True щоб уникнути мультиколінеарності.\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    print(f\"\\nЗакодовані категоріальні колонки: {cat_cols} -> one-hot (drop_first=True)\")\n",
    "else:\n",
    "    print('\\nКатегоріальних колонок type/region не знайдено для кодування')\n",
    "\n",
    "\n",
    "# Перейменувати колонки 4046, 4225, 4770 (PLU-коди) \n",
    "plu_codes = ['4046', '4225', '4770']\n",
    "# Стовпці можуть бути рядками або числами. Зробимо універсальне перейменування.\n",
    "rename_map = {}\n",
    "for col in df.columns:\n",
    "    col_str = str(col)\n",
    "    if col_str in plu_codes:\n",
    "        rename_map[col] = f'plu_{col_str}'\n",
    "if rename_map:\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "    print('\\nПерейменовано PLU-колонки:', rename_map)\n",
    "else:\n",
    "    print('\\nPLU-колонки 4046/4225/4770 не знайдено або вже перейменовано')\n",
    "\n",
    "# Очищення даних: пропуски та дублікатні рядки \n",
    "# Пропуски\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "if not missing.empty:\n",
    "    print('\\nЗнайдені пропуски по колонках:')\n",
    "    print(missing)\n",
    "    # Для числових колонок заповнюємо медіаною, для категоріальних - модою\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Не чіпаємо ціль, якщо у ній є пропуски - це краще розглянути окремо\n",
    "    if TARGET in num_cols:\n",
    "        num_cols.remove(TARGET)\n",
    "    for c in missing.index:\n",
    "        if c in num_cols:\n",
    "            med = df[c].median()\n",
    "            df[c].fillna(med, inplace=True)\n",
    "            print(f\"Заповнено пропуски в числовій колонці {c} медианою: {med}\")\n",
    "        else:\n",
    "            mode = df[c].mode()\n",
    "            if not mode.empty:\n",
    "                df[c].fillna(mode.iloc[0], inplace=True)\n",
    "                print(f\"Заповнено пропуски в колонці {c} модою: {mode.iloc[0]}\")\n",
    "            else:\n",
    "                df[c].fillna('', inplace=True)\n",
    "                print(f\"Заповнено пропуски в колонці {c} пустим рядком\")\n",
    "else:\n",
    "    print('\\nПропусків у датасеті не знайдено')\n",
    "\n",
    "# Дублікатні рядки\n",
    "n_dup = df.duplicated().sum()\n",
    "if n_dup:\n",
    "    print(f\"\\nЗнайдено {n_dup} дублікатів. Видаляю...\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "else:\n",
    "    print('\\nДублікатів не знайдено')\n",
    "\n",
    "# Масштабувати числові ознаки \n",
    "# Для SVR масштабування важливе. Масштабуємо всі числові колонки, крім цільової TARGET.\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET in num_cols:\n",
    "    num_cols.remove(TARGET)\n",
    "\n",
    "if num_cols:\n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    print('\\nМасштабовано числові ознаки (StandardScaler). Кількість колонок:', len(num_cols))\n",
    "else:\n",
    "    print('\\nЧислових колонок для масштабування не знайдено')\n",
    "\n",
    "# Збереження результату \n",
    "df.to_csv(SAVE_PATH, index=False)\n",
    "print(f\"\\nПідготовка завершена. Збережено: {SAVE_PATH}\")\n",
    "print('\\nРозміри після підготовки:', df.shape)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d50fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 2.1. Візуалізація окремих стовпців\n",
    "# ------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
